# controlnet_TrainingPackageï¼ˆcontrolnetæ¨¡å‹è®­ç»ƒåŒ…ï¼‰


## ä»‹ç»

ğŸ¤–ï¸ ä¸€ç§åˆ©ç”¨pytorch lightingè®­ç»ƒcontrolnetæ¨¡å‹çš„å·¥å…·åŒ…ã€‚

ğŸ’¡ ç°åœ¨æ²¡æœ‰å¾ˆæ–¹ä¾¿çš„è®©ç”¨æˆ·è‡ªå·±è®­ç»ƒcontrolnetæ¨¡å‹çš„å·¥å…·åŒ…ï¼Œæ‰€ä»¥è¿™ä¸ªå·¥å…·åŒ…å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜è€Œç”Ÿçš„ã€‚

ğŸ“¦ å·¥å…·åŒ…åŒ…å«ï¼š

* è®­ç»ƒè„šæœ¬ï¼ˆå¯ä»¥ç›´æ¥ç”¨è„šæœ¬è®­ç»ƒï¼‰
* è®­ç»ƒåŒ…çš„UIç•Œé¢ï¼ˆéå¸¸ç›´è§‚çš„å¡«å†™å‚æ•°ï¼‰
* è®­ç»ƒæ•°æ®
* è®­ç»ƒå°å·¥å…·ï¼ˆåŒ…æ‹¬ä¸€é”®è®­ç»ƒé›†å‘½åã€ä¸€é”®ç”Ÿæˆprompt.jsonç­‰ï¼‰

âœ… å·¥å…·åŒ…ç‰¹ç‚¹ï¼š
* æ–¹ä¾¿å®ç”¨ï¼Œè„šæœ¬æˆ–è€…UIç•Œé¢éƒ½å¯ä»¥å¯åŠ¨
* ç›®å‰ä»…æ”¯æŒè®­ç»ƒSD1.5çš„controlnetæ¨¡å‹

## å®‰è£…æ–¹æ³•

éœ€è¦æœ‰pythonç‰ˆæœ¬ï¼š3.8ã€‚

1. å»ºç«‹è™šæ‹Ÿç¯å¢ƒ+å®‰è£…ä¾èµ–ã€‚
- è¿™ä¸€æ­¥å¯ä»¥æ‰‹åŠ¨åˆ›å»ºï¼Œä¹Ÿå¯ä»¥åŒå‡»â€œsetup.batâ€ä¸€é”®å®‰è£…ã€‚
- å®‰è£…å®Œç¯å¢ƒä¾èµ–åï¼Œå°±å¯ä»¥ç›´æ¥ç”¨è„šæœ¬è®­ç»ƒæ¨¡å‹ã€‚
  - é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰€æœ‰å¸¦â€œ_parâ€åç¼€çš„.pyæ–‡ä»¶éƒ½æ˜¯è„šæœ¬ã€‚
  - å…¶ä¸­â€œcontrolnet_sd15_train_par.pyâ€æ˜¯è®­ç»ƒè„šæœ¬ã€‚
2. ä½¿ç”¨UIç•Œé¢ï¼Œéœ€è¦æœ‰npmã€‚
- â€œsetup.batâ€å¯ä»¥ä¸€é”®å®‰è£…æ‰€æœ‰ä¾èµ–ã€‚å®‰è£…å®Œåå¯ä»¥ç”¨UIç•Œé¢è®­ç»ƒæ¨¡å‹ã€‚
3. ä¸‹è½½æ¨¡å‹ï¼ˆå¿…é¡»ï¼‰
- æ¨¡å‹ä¸‹è½½åœ°å€ï¼šhttps://huggingface.co/lllyasviel/ControlNet/tree/main/models
  - éœ€è¦ä¸‹è½½â€œpytorch_model.binâ€æ–‡ä»¶
- ä¸‹è½½å®Œæ¨¡å‹åï¼Œéœ€è¦å°†æ¨¡å‹æ”¾åˆ°æ ¹ç›®å½•çš„â€œclip-vit-large-patch14â€æ–‡ä»¶å¤¹ä¸‹ã€‚
4. ä¸‹è½½è®­ç»ƒæ—¶çš„baseæ¨¡å‹ï¼ˆå¿…é¡»ï¼‰
- æ¨¡å‹ä¸‹è½½åœ°å€ï¼šhttps://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main
  - éœ€è¦ä¸‹è½½â€œv1-5-pruned.ckptâ€æ–‡ä»¶
  - ä¸‹è½½å®Œæ¨¡å‹åï¼Œå°†æ¨¡å‹ä»»æ„å¦¥å–„æ–‡ä»¶å¤¹ä¸‹

## UIç•Œé¢

![è®­ç»ƒä¸»ç•Œé¢](img/1.png)
![æ¨¡å‹é¢„å¤„ç†ç•Œé¢](img/2.png)
![å°å·¥å…·ç•Œé¢](img/3.png)

## è®­ç»ƒæµç¨‹

1. åˆ¶ä½œè®­ç»ƒé›†ï¼Œå‡†å¤‡åŸå§‹å›¾ç‰‡ã€æ¡ä»¶å›¾ç‰‡ä¸ç›®æ ‡å›¾ç‰‡ï¼›
- controlnetæ¨¡å‹éœ€è¦å‡†å¤‡åŸå§‹å›¾ç‰‡ï¼Œæ¡ä»¶å›¾ç‰‡ä»¥åŠç›®æ ‡ç”Ÿæˆå›¾ç‰‡ï¼Œè¿™ä¸‰æ ·ç¼ºä¸€ä¸å¯ã€‚
- åŸå§‹å›¾ç‰‡æ˜¯æŒ‡ä»ä»€ä¹ˆå›¾ç‰‡ä¸­æå–ç‰¹å¾ï¼Œå°±æ˜¯ä½ æ”¾åˆ°webuiçš„controlnetæ’ä»¶ä¸­çš„å›¾ç‰‡ï¼›
- æ¡ä»¶å›¾ç‰‡æ˜¯æŒ‡ä»åŸå§‹å›¾ç‰‡ä¸­æå–çš„ç‰¹å¾å›¾ç‰‡ï¼Œå°±æ˜¯é‚£ç§ä½ åœ¨webuiçš„controlnetæ’ä»¶ä¸­æŒ‰ä¸‹çˆ†ç‚¸å›¾æ ‡åç”Ÿæˆçš„å›¾ç‰‡ï¼›
- ç›®æ ‡å›¾ç‰‡æ˜¯æŒ‡ä½ ç”¨controlnetåå¸Œæœ›ç”Ÿæˆçš„å›¾ç‰‡ã€‚
2. æ¡ä»¶å›¾ç‰‡æ”¾åˆ°â€œsourceâ€æ–‡ä»¶å¤¹ä¸­ï¼Œç›®æ ‡å›¾ç‰‡æ”¾åˆ°â€œtargetâ€æ–‡ä»¶å¤¹ä¸­ï¼ˆæ–‡ä»¶å¤¹çš„å‘½åä¸€å®šè¦éå¸¸å‡†ç¡®ï¼‰ï¼›
3. ä½¿ç”¨å°å·¥å…·åˆ¶ä½œprompt.jsæ–‡ä»¶ï¼›
4. å°†sdæ¨¡å‹è¿›è¡Œé¢„å¤„ç†ï¼›
5. è¾“å…¥å‚æ•°è¿›è¡Œè®­ç»ƒï¼›
6. è®­ç»ƒå®Œæ¯•è¿›è¡Œæ£€éªŒã€‚

---

## Introduction



ğŸ¤– A toolkit for training control net models using pytorch lighting.



ğŸ’¡ There is currently no convenient toolkit for users to train their own ControlNet models, so this toolkit was developed to address this issue.



ğŸ“¦ The toolkit includes:



* Training script (can be directly used for training)

* UI interface of training package (very intuitive for filling in parameters)

* Training data

* Training tools (including one click training set naming, one click generating prompt. json, etc.)



âœ… Tool kit features:

* Convenient and practical, scripts or UI interfaces can be launched

* Currently, only training SD1.5's controllnet model is supported



##Installation method



Python version 3.8 is required.



1. Establish a virtual environment and install dependencies.

- This step can be manually created or double clicked on "setup. bat" for one click installation.

- After installing the environment dependencies, you can directly train the model using scripts.

- All. py files with the suffix "_par" in the root directory of the project are scripts.

- Among them, "controllet_sd15_train_par. py" is the training script.

2. To use the UI interface, NPM is required.

- "Setup. bat" can install all dependencies with just one click. After installation, the model can be trained using the UI interface.

3. Download model (mandatory)

- Model download address: https://huggingface.co/lllyasviel/ControlNet/tree/main/models

- Need to download the "pytorch_model. bin" file

- After downloading the model, you need to place it in the "clip vit target patch14" folder in the root directory.

4. Download the base model for training (mandatory)

- Model download address: https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main

- Need to download the "v1-5 pruned. ckpt" file

- After downloading the model, place it in any appropriate folder


##UI interface


! [Training Main Interface] (img/1. png)

! [Model Preprocessing Interface] (img/2. png)

! [Widget Interface] (img/3. png)



##Training process


1. Create a training set, prepare original images, conditional images, and target images;

- The controllnet model requires the preparation of raw images, conditional images, and target generated images, all of which are indispensable.

- The original image refers to the image from which features are extracted, which is the image you put in the Controlnet plugin of the webui;

- Conditional images refer to feature images extracted from the original image, which are the images generated by pressing the explosion icon in the Controlnet plugin of WebUI;

- The target image refers to the image you want to generate after using ControlNet.

2. Place the conditional image in the "source" folder and the target image in the "target" folder (the folder name must be very accurate);

3. Use small tools to create the prompt.js file;

4. Preprocess the SD model;

5. Input parameters for training;

6. Conduct testing after training is completed.
